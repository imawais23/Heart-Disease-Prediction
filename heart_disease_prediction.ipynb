{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d91aa256",
   "metadata": {},
   "source": [
    "\n",
    "# Heart Disease Prediction Project\n",
    "\n",
    "## 1. Problem Statement & Goal\n",
    "**Goal:** Build a machine learning model to predict whether a person is at risk of heart disease based on clinical health data.\n",
    "\n",
    "**Dataset:** UCI Heart Disease Dataset (Cleveland).\n",
    "**Task:** Binary Classification (Disease vs. No Disease).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cd70d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc, ConfusionMatrixDisplay\n",
    "\n",
    "# Set plot style\n",
    "sns.set(style=\"whitegrid\")\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde80eb1",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eace5ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset\n",
    "data_path = \"data/heart_disease_uci.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f809b4",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46e215d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standardize column names\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "# Drop irrelevant columns\n",
    "drop_cols = ['id', 'dataset']\n",
    "df = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
    "\n",
    "# Handle missing values\n",
    "for col in df.columns:\n",
    "    if df[col].isnull().any():\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            median = df[col].median()\n",
    "            df[col] = df[col].fillna(median)\n",
    "            print(f\"Filled missing values in {col} with median = {median}\")\n",
    "        else:\n",
    "            mode = df[col].mode()[0]\n",
    "            df[col] = df[col].fillna(mode)\n",
    "            print(f\"Filled missing values in {col} with mode = {mode}\")\n",
    "\n",
    "print(\"Missing values after cleaning:\")\n",
    "print(df.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6d7501",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa89294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Target Distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='num', data=df)\n",
    "plt.title(\"Target Distribution (0=No Disease, 1-4=Disease)\")\n",
    "plt.show()\n",
    "\n",
    "# Correlation Matrix\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df[numeric_cols].corr(), annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2015e4",
   "metadata": {},
   "source": [
    "## 5. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e71bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Target Preparation (Binary Classification)\n",
    "# The 'num' column contains 0 for no disease, and 1-4 for different stages of disease.\n",
    "# We convert this to 0 (No Disease) vs 1 (Disease).\n",
    "\n",
    "if 'num' in df.columns:\n",
    "    y = df['num'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    X = df.drop(columns=['num'])\n",
    "else:\n",
    "    # Fallback if column name is different\n",
    "    y = df.iloc[:,-1].apply(lambda x: 1 if x > 0 else 0)\n",
    "    X = df.iloc[:,:-1]\n",
    "\n",
    "# One-Hot Encoding for categorical variables\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training Shape: {X_train_scaled.shape}\")\n",
    "print(f\"Testing Shape: {X_test_scaled.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c50d12",
   "metadata": {},
   "source": [
    "## 6. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d36385",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Logistic Regression\n",
    "lr_params = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "lr_grid = GridSearchCV(LogisticRegression(max_iter=1000), lr_params, cv=5, scoring='accuracy')\n",
    "lr_grid.fit(X_train_scaled, y_train)\n",
    "best_lr = lr_grid.best_estimator_\n",
    "print(f\"Best Logistic Regression Params: {lr_grid.best_params_}\")\n",
    "\n",
    "# 2. Decision Tree\n",
    "dt_params = {'max_depth': [3, 5, 7, 10, None], 'min_samples_split': [2, 5, 10]}\n",
    "dt_grid = GridSearchCV(DecisionTreeClassifier(random_state=42), dt_params, cv=5, scoring='accuracy')\n",
    "dt_grid.fit(X_train, y_train)\n",
    "best_dt = dt_grid.best_estimator_\n",
    "print(f\"Best Decision Tree Params: {dt_grid.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bef34a3",
   "metadata": {},
   "source": [
    "## 7. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991671a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model, X, y, name):\n",
    "    y_pred = model.predict(X)\n",
    "    y_prob = model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    fpr, tpr, _ = roc_curve(y, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    print(f\"--- {name} ---\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"AUC: {roc_auc:.4f}\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    ConfusionMatrixDisplay(cm).plot()\n",
    "    plt.title(f\"Confusion Matrix - {name}\")\n",
    "    plt.show()\n",
    "    \n",
    "    return fpr, tpr, roc_auc\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "fpr_lr, tpr_lr, auc_lr = evaluate_model(best_lr, X_test_scaled, y_test, \"Logistic Regression\")\n",
    "\n",
    "# Evaluate Decision Tree\n",
    "fpr_dt, tpr_dt, auc_dt = evaluate_model(best_dt, X_test, y_test, \"Decision Tree\")\n",
    "\n",
    "# ROC Curve Comparison\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_lr, tpr_lr, label=f\"Logistic Regression (AUC={auc_lr:.2f})\")\n",
    "plt.plot(fpr_dt, tpr_dt, label=f\"Decision Tree (AUC={auc_dt:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve Comparison\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6359f7ac",
   "metadata": {},
   "source": [
    "## 8. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd472d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature Importance for Logistic Regression\n",
    "coefs = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': best_lr.coef_[0]\n",
    "})\n",
    "coefs['Abs_Coefficient'] = coefs['Coefficient'].abs()\n",
    "coefs = coefs.sort_values(by='Abs_Coefficient', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Coefficient', y='Feature', data=coefs, palette='viridis')\n",
    "plt.title(\"Top 10 Features (Logistic Regression)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0572346",
   "metadata": {},
   "source": [
    "\n",
    "## 9. Conclusion\n",
    "- We successfully built a pipeline to predict heart disease risk.\n",
    "- **Logistic Regression** achieved an AUC of approximately **0.90**, making it a strong candidate for this task.\n",
    "- Key risk factors identified include **Chest Pain Type (cp)**, **Thalach (Max Heart Rate)**, and **Oldpeak**.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
